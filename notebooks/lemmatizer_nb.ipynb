{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ElementTree\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import sys, re\n",
    "\n",
    "\n",
    "TAGS = {'NOUN': 'S',\n",
    "        'ADJF': 'A',\n",
    "        'ADJS': 'A',\n",
    "        'VERB': 'V',\n",
    "        'INFN': 'V',\n",
    "        'PRTF': 'V',\n",
    "        'PRTS': 'V',\n",
    "        'GRND': 'V',\n",
    "        'COMP': 'ADV',\n",
    "        'NUMR': 'ADV',\n",
    "        'NPRO': 'S',\n",
    "        'PRED': 'ADV',\n",
    "        'PREP': 'PR',\n",
    "        'CONJ': 'CONJ',\n",
    "        'PRCL': 'ADV',\n",
    "        'INTJ': 'ADV'}\n",
    "\n",
    "\n",
    "CONJ = ['а', 'но', 'да', 'зато', 'однако', 'и', 'также', 'тоже', 'или', 'либо', 'то', 'ли', 'же', 'притом', 'причём']\n",
    "PR = ['без', 'в', 'для', 'за', 'из', 'к', 'на', 'над', 'о', 'об', 'от', 'по', 'под', 'пред', 'при', 'про', 'с', 'у', 'через']\n",
    "\n",
    "\n",
    "def xml_to_dict(xml: Path):\n",
    "    print('Parsing xml with dictionary...', file=sys.stderr)\n",
    "\n",
    "    tree = ElementTree.parse(xml)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    lemmas: Dict[int, str] = {}\n",
    "    for lemma in root.iter('lemma'):\n",
    "        lemmas[int(lemma.get('id'))] = lemma.find('l').get('t')\n",
    "\n",
    "    full_lemmas: Dict[str, str] = {}\n",
    "    for link in root.iter('link'):\n",
    "        id_from, id_to = int(link.get('from')), int(link.get('to'))\n",
    "        full_lemmas[lemmas[id_to]] = lemmas[id_from]\n",
    "\n",
    "    word_dict : Dict[str, List[Tuple]] = {}\n",
    "    for lemma in root.iter('lemma'):\n",
    "        lem = lemma.find('l').get('t')\n",
    "        tags = [TAGS[tag.get('v')] for tag in lemma.find('l').iter('g') if tag.get('v') in TAGS]\n",
    "        lem_tag = tags[0] if len(tags) > 0 else 'ADV'\n",
    "\n",
    "        if (lem_tag == 'V' or lem_tag == 'A') and lem in full_lemmas:\n",
    "            lem = full_lemmas[lem]\n",
    "\n",
    "        for word in lemma.iter('f'):\n",
    "            w = word.get('t')\n",
    "            if w not in word_dict:\n",
    "                word_dict[w] = []\n",
    "            word_dict[w].append((lem, lem_tag))\n",
    "\n",
    "    print('Done', file=sys.stderr)\n",
    "\n",
    "    return word_dict\n",
    "\n",
    "\n",
    "def lemmatize_sentence(sentence: List, word_dict: Dict):\n",
    "    lemmatized_words = []\n",
    "    for word in sentence:\n",
    "        norm_word = word.lower()\n",
    "        if word.isalpha():\n",
    "            if norm_word in CONJ:\n",
    "                lemma = '{' + f'{norm_word}=CONJ' + '}'\n",
    "                lemmatized_words.append(f'{word}{lemma}')\n",
    "            elif norm_word in PR:\n",
    "                lemma = '{' + f'{norm_word}=PR' + '}'\n",
    "                lemmatized_words.append(f'{word}{lemma}')\n",
    "            elif norm_word in word_dict:\n",
    "                lemma = '{' + '{}={}'.format(*word_dict[norm_word][0]) + '}'\n",
    "                lemmatized_words.append(f'{word}{lemma}')\n",
    "            else:\n",
    "                lemma = '{' + f'{norm_word}=ADV' + '}'\n",
    "                lemmatized_words.append(f'{word}{lemma}')\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "def process_dataset(dataset_path: Path, output_path: Path, word_dict: Dict):\n",
    "    if not output_path.parent.exists():\n",
    "        output_path.parent.mkdir(parents=True)\n",
    "\n",
    "    with dataset_path.open('r') as dataset, output_path.open('w') as output:\n",
    "        for i, line in enumerate(dataset.readlines()):\n",
    "            if i % 20 == 0:\n",
    "                print(f'Lemmatized {i} sentences', file=sys.stderr)\n",
    "            sentence = re.sub(r'[^а-яёА-ЯË]', ' ', line).strip().split()\n",
    "            result = lemmatize_sentence(sentence, word_dict)\n",
    "            print(result, file=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = Path('resources', 'opencorpora', 'dict.opcorpora.xml')\n",
    "dataset_path = Path('resources', 'dataset', 'dataset_37845_1.txt')\n",
    "output_path = Path('resources', 'output', 'output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing xml with dictionary...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_dict = xml_to_dict(dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatized 0 sentences\n",
      "Lemmatized 20 sentences\n",
      "Lemmatized 40 sentences\n",
      "Lemmatized 60 sentences\n",
      "Lemmatized 80 sentences\n",
      "Lemmatized 100 sentences\n",
      "Lemmatized 120 sentences\n",
      "Lemmatized 140 sentences\n",
      "Lemmatized 160 sentences\n",
      "Lemmatized 180 sentences\n"
     ]
    }
   ],
   "source": [
    "process_dataset(dataset_path, output_path, word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
